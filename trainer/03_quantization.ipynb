{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de01d98-8561-4a46-86da-199a272537b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-22 17:09:08.463131: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "\n",
    "# Data path\n",
    "DATA_DIR = \"data/TinyDataset/trainData/\"\n",
    "IMAGE_SIZE = (112, 112)\n",
    "\n",
    "# Outputs paths\n",
    "MODEL_ID = \"QA_model\"\n",
    "\n",
    "MODEL_PATH = f\"models/{MODEL_ID}\"\n",
    "MODEL_TFLITE_PATH = f\"outputs/{MODEL_ID}/model.tflite\"\n",
    "MODEL_QUANT_PATH = f\"outputs/{MODEL_ID}/model_quant.tflite\"\n",
    "MODEL_QUANT_INT_FLOAT_PATH = f\"outputs/{MODEL_ID}/model_quant_int_float.tflite\"\n",
    "MODEL_QUANT_FUL_INT_PATH = f\"outputs/{MODEL_ID}/model_quant_full_int.tflite\"\n",
    "\n",
    "\n",
    "# A small util\n",
    "def store_model(model, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97a2d8",
   "metadata": {},
   "source": [
    "As part of the transformation process, in order ot estimate quantization values, we need to feed the converter some of the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facc7acf-dd21-4a8d-acd8-b5310dca0fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 242 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "class_names = sorted( [ d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))] )\n",
    "\n",
    "# Load the dataset\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=class_names,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# This is a standard preprocessing function\n",
    "preprocessing = keras.Sequential([keras.layers.Rescaling(scale=1.0 / 255.0)])\n",
    "\n",
    "# Apply the preprocessing\n",
    "dataset = dataset.map(lambda x, y: (preprocessing(x, training=True), y))\n",
    "\n",
    "# Define the feeding data for the converter\n",
    "def representative_dataset():\n",
    "    for images, _ in dataset.take(256):\n",
    "        yield [images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8afa5e",
   "metadata": {},
   "source": [
    "# 1. Transform models:\n",
    "\n",
    "Here we are showing the transformation from a pre-trained `tf-keras` model into the `tflite` and `tf-lite-quant` versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcdbdfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"QATModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Backbone (KerasLayer)       (None, 256)               218544    \n",
      "                                                                 \n",
      " quant_BatchNorm1 (Quantize  (None, 256)               1031      \n",
      " WrapperV2)                                                      \n",
      "                                                                 \n",
      " quant_Output (QuantizeWrap  (None, 6)                 1547      \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221122 (863.76 KB)\n",
      "Trainable params: 215126 (840.34 KB)\n",
      "Non-trainable params: 5996 (23.42 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model from pre-trained checkpoint\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05470115",
   "metadata": {},
   "source": [
    "## 1. Standard TF-LITE:\n",
    "This is a `tflite` model, still using `float32` for all parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad891378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpm8lvj95j/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpm8lvj95j/assets\n",
      "2024-01-22 12:35:13.350011: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-22 12:35:13.350032: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-22 12:35:13.351999: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpm8lvj95j\n",
      "2024-01-22 12:35:13.365549: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-22 12:35:13.365569: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpm8lvj95j\n",
      "2024-01-22 12:35:13.400229: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-01-22 12:35:13.414535: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-22 12:35:13.800085: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpm8lvj95j\n",
      "2024-01-22 12:35:13.972949: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 620951 microseconds.\n",
      "2024-01-22 12:35:14.177994: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 95, % non-converted = 63.16 %\n",
      " * 60 ARITH ops\n",
      "\n",
      "- arith.constant:   60 occurrences  (f32: 58, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "store_model(tflite_model, MODEL_TFLITE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249aed2d",
   "metadata": {},
   "source": [
    "## 2. Dynamic range quantization\n",
    "\n",
    "Here we are still using `float32` for input and output, but most of the weights will be converted to `8-bit` precision. Activations are also quantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54278e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp9dw6hx1b/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp9dw6hx1b/assets\n",
      "2024-01-22 12:35:45.912596: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-22 12:35:45.912614: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-22 12:35:45.912853: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp9dw6hx1b\n",
      "2024-01-22 12:35:45.922167: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-22 12:35:45.922180: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp9dw6hx1b\n",
      "2024-01-22 12:35:45.955805: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-22 12:35:46.287140: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp9dw6hx1b\n",
      "2024-01-22 12:35:46.421955: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 509101 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 41, Total Ops 95, % non-converted = 43.16 %\n",
      " * 41 ARITH ops\n",
      "\n",
      "- arith.constant:   41 occurrences  (f32: 39, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 19)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_quant = converter.convert()\n",
    "store_model(tflite_model_quant, MODEL_QUANT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3bdab",
   "metadata": {},
   "source": [
    "## 3. Full integer quantization\n",
    "\n",
    "Basically here we are quantisizing also quantizing activations ( and input/output ). Fro this we need to calibrate the quantization of those values, and hence, we need to feed some data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8beb4",
   "metadata": {},
   "source": [
    "### 3.1 Integer with float fallback:\n",
    "\n",
    "Here we are still using float implementation when integer ops are not available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4658d3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpciiqjiku/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpciiqjiku/assets\n",
      "/Users/vvcastro/.conda/envs/arduino/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-22 12:36:04.780678: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-22 12:36:04.780694: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-22 12:36:04.780916: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpciiqjiku\n",
      "2024-01-22 12:36:04.791602: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-22 12:36:04.791619: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpciiqjiku\n",
      "2024-01-22 12:36:04.828152: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-22 12:36:05.164112: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpciiqjiku\n",
      "2024-01-22 12:36:05.320144: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 539229 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 95, % non-converted = 63.16 %\n",
      " * 60 ARITH ops\n",
      "\n",
      "- arith.constant:   60 occurrences  (f32: 58, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.float16,\n",
    "]\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter.convert()\n",
    "store_model(tflite_quant_model, MODEL_QUANT_INT_FLOAT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e7eb6",
   "metadata": {},
   "source": [
    "### 3.3 Integer only:\n",
    "\n",
    "Finally, this is a model with `input` and `output` as `uint8`. This should reduce memory usage to its maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "413c58ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp9pwfjdx9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp9pwfjdx9/assets\n",
      "/Users/vvcastro/.conda/envs/arduino/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-22 17:12:21.076206: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-22 17:12:21.076251: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-22 17:12:21.077592: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp9pwfjdx9\n",
      "2024-01-22 17:12:21.101587: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-22 17:12:21.101688: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp9pwfjdx9\n",
      "2024-01-22 17:12:21.153827: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-01-22 17:12:21.177277: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-22 17:12:21.744651: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp9pwfjdx9\n",
      "2024-01-22 17:12:21.995779: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 918194 microseconds.\n",
      "2024-01-22 17:12:22.261952: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 101, % non-converted = 59.41 %\n",
      " * 60 ARITH ops\n",
      "\n",
      "- arith.constant:   60 occurrences  (f32: 58, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (uq_8: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (uq_8: 1, uq_32: 1)\n",
      "  (uq_8: 1)\n",
      "  (uq_8: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "store_model(tflite_model, MODEL_QUANT_FUL_INT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9530b9c0",
   "metadata": {},
   "source": [
    "Finally, this will export the model as a set of bytes for operating in the arduino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4415d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -n model_tflite -i {MODEL_QUANT_FUL_INT_PATH} > outputs/{MODEL_ID}.cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff215601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
