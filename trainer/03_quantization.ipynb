{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de01d98-8561-4a46-86da-199a272537b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 22:26:05.849859: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "\n",
    "# Data path\n",
    "DATA_DIR = \"data/TinyDataset/trainData\"\n",
    "IMAGE_SIZE = (112, 112)\n",
    "\n",
    "# Outputs paths\n",
    "MODEL_ID = \"QA_model\"\n",
    "\n",
    "MODEL_PATH = \"models/quant_model\"\n",
    "MODEL_TFLITE_PATH = f\"outputs/{MODEL_ID}/model.tflite\"\n",
    "MODEL_QUANT_PATH = f\"outputs/{MODEL_ID}/model_quant.tflite\"\n",
    "MODEL_QUANT_INT_FLOAT_PATH = f\"outputs/{MODEL_ID}/model_quant_int_float.tflite\"\n",
    "MODEL_QUANT_FUL_INT_PATH = f\"outputs/{MODEL_ID}/model_quant_full_int.tflite\"\n",
    "\n",
    "\n",
    "# A small util\n",
    "def store_model(model, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97a2d8",
   "metadata": {},
   "source": [
    "As part of the transformation process, in order ot estimate quantization values, we need to feed the converter some of the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "facc7acf-dd21-4a8d-acd8-b5310dca0fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 242 files belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "class_names = sorted( [ d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))] )\n",
    "\n",
    "# Load the dataset\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=class_names,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "# This is a standard preprocessing function\n",
    "preprocessing = keras.Sequential([keras.layers.Rescaling(scale=1.0 / 255.0)])\n",
    "\n",
    "# Apply the preprocessing\n",
    "dataset = dataset.map(lambda x, y: (preprocessing(x, training=True), y))\n",
    "\n",
    "# Define the feeding data for the converter\n",
    "def representative_dataset():\n",
    "    for images, _ in dataset.take(100):\n",
    "        yield [images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8afa5e",
   "metadata": {},
   "source": [
    "# 1. Transform models:\n",
    "\n",
    "Here we are showing the transformation from a pre-trained `tf-keras` model into the `tflite` and `tf-lite-quant` versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcdbdfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"QAModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Backbone (KerasLayer)       (None, 256)               218544    \n",
      "                                                                 \n",
      " quantize_layer_20 (Quantiz  (None, 256)               3         \n",
      " eLayer)                                                         \n",
      "                                                                 \n",
      " quant_BatchNorm1 (Quantize  (None, 256)               1031      \n",
      " WrapperV2)                                                      \n",
      "                                                                 \n",
      " quant_Output (QuantizeWrap  (None, 6)                 1547      \n",
      " perV2)                                                          \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221125 (863.77 KB)\n",
      "Trainable params: 215126 (840.34 KB)\n",
      "Non-trainable params: 5999 (23.43 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model from pre-trained checkpoint\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05470115",
   "metadata": {},
   "source": [
    "## 1. Standard TF-LITE:\n",
    "This is a `tflite` model, still using `float32` for all parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad891378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpwi89szb8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpwi89szb8/assets\n",
      "2024-01-21 22:27:13.898849: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-21 22:27:13.898868: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-21 22:27:13.899082: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpwi89szb8\n",
      "2024-01-21 22:27:13.910872: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-21 22:27:13.910890: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpwi89szb8\n",
      "2024-01-21 22:27:13.951327: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-21 22:27:14.327693: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpwi89szb8\n",
      "2024-01-21 22:27:14.497774: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 598693 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 62, Total Ops 107, % non-converted = 57.94 %\n",
      " * 62 ARITH ops\n",
      "\n",
      "- arith.constant:   62 occurrences  (f32: 60, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (uq_8: 4)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "store_model(tflite_model, MODEL_TFLITE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249aed2d",
   "metadata": {},
   "source": [
    "## 2. Dynamic range quantization\n",
    "\n",
    "Here we are still using `float32` for input and output, but most of the weights will be converted to `8-bit` precision. Activations are also quantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54278e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmphesfgqz9/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmphesfgqz9/assets\n",
      "/Users/vvcastro/.conda/envs/arduino/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-21 22:27:29.268689: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-21 22:27:29.268707: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-21 22:27:29.268906: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmphesfgqz9\n",
      "2024-01-21 22:27:29.283027: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-21 22:27:29.283045: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmphesfgqz9\n",
      "2024-01-21 22:27:29.332084: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-21 22:27:29.713693: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmphesfgqz9\n",
      "2024-01-21 22:27:29.885882: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 616975 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 103, % non-converted = 58.25 %\n",
      " * 60 ARITH ops\n",
      "\n",
      "- arith.constant:   60 occurrences  (f32: 58, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 2)\n",
      "  (uq_8: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (uq_8: 1, uq_32: 1)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_quant = converter.convert()\n",
    "store_model(tflite_model_quant, MODEL_QUANT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3bdab",
   "metadata": {},
   "source": [
    "## 3. Full integer quantization\n",
    "\n",
    "Basically here we are quantisizing also quantizing activations ( and input/output ). Fro this we need to calibrate the quantization of those values, and hence, we need to feed some data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8beb4",
   "metadata": {},
   "source": [
    "### 3.1 Integer with float fallback:\n",
    "\n",
    "Here we are still using float implementation when integer ops are not available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4658d3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpcq_wr2b_/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpcq_wr2b_/assets\n",
      "/Users/vvcastro/.conda/envs/arduino/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-21 22:27:44.892123: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-21 22:27:44.892144: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-21 22:27:44.892349: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpcq_wr2b_\n",
      "2024-01-21 22:27:44.907264: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-21 22:27:44.907283: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpcq_wr2b_\n",
      "2024-01-21 22:27:44.955429: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-21 22:27:45.337701: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpcq_wr2b_\n",
      "2024-01-21 22:27:45.509173: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 616823 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 103, % non-converted = 58.25 %\n",
      " * 60 ARITH ops\n",
      "\n",
      "- arith.constant:   60 occurrences  (f32: 58, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 2)\n",
      "  (uq_8: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (uq_8: 1, uq_32: 1)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.float16,\n",
    "]\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter.convert()\n",
    "store_model(tflite_quant_model, MODEL_QUANT_INT_FLOAT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e7eb6",
   "metadata": {},
   "source": [
    "### 3.3 Integer only:\n",
    "\n",
    "Finally, this is a model with `input` and `output` as `uint8`. This should reduce memory usage to its maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413c58ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpikjmkaq4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpikjmkaq4/assets\n",
      "/Users/vvcastro/.conda/envs/arduino/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-21 22:28:11.416427: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-21 22:28:11.416445: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-21 22:28:11.416643: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpikjmkaq4\n",
      "2024-01-21 22:28:11.429579: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-21 22:28:11.429614: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpikjmkaq4\n",
      "2024-01-21 22:28:11.473472: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-21 22:28:11.870943: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpikjmkaq4\n",
      "2024-01-21 22:28:12.043889: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 627246 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 103, % non-converted = 58.25 %\n",
      " * 60 ARITH ops\n",
      "\n",
      "- arith.constant:   60 occurrences  (f32: 58, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 2)\n",
      "  (uq_8: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "  (uq_8: 1, uq_32: 1)\n",
      "  (uq_8: 2)\n",
      "  (uq_8: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "store_model(tflite_model, MODEL_QUANT_FUL_INT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9530b9c0",
   "metadata": {},
   "source": [
    "Finally, this will export the model as a set of bytes for operating in the arduino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4415d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -n model_tflite -i {MODEL_QUANT_FUL_INT_PATH} > outputs/{MODEL_ID}_model.cc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
