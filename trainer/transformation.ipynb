{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6de01d98-8561-4a46-86da-199a272537b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import os\n",
    "\n",
    "# Data path\n",
    "DATA_DIR = \"data/trainData\"\n",
    "IMAGE_SIZE = (112, 112)\n",
    "\n",
    "# Outputs paths\n",
    "MODEL_ID = \"base\"\n",
    "\n",
    "MODEL_PATH = \"models/trained_model\"\n",
    "MODEL_TFLITE_PATH = f\"outputs/{MODEL_ID}/model.tflite\"\n",
    "MODEL_QUANT_PATH = f\"outputs/{MODEL_ID}/model_quant.tflite\"\n",
    "MODEL_QUANT_INT_FLOAT_PATH = f\"outputs/{MODEL_ID}/model_quant_int_float.tflite\"\n",
    "MODEL_QUANT_FUL_INT_PATH = f\"outputs/{MODEL_ID}/model_quant_full_int.tflite\"\n",
    "\n",
    "\n",
    "# A small util\n",
    "def store_model(model, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c97a2d8",
   "metadata": {},
   "source": [
    "As part of the transformation process, in order ot estimate quantization values, we need to feed the converter some of the train data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "facc7acf-dd21-4a8d-acd8-b5310dca0fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14457 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "class_names = sorted(os.listdir(DATA_DIR))\n",
    "\n",
    "# Load the dataset\n",
    "dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "    DATA_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    class_names=class_names,\n",
    "    color_mode=\"rgb\",\n",
    "    image_size=IMAGE_SIZE,\n",
    "    batch_size=1,\n",
    ")\n",
    "\n",
    "# This is a standard preprocessing function\n",
    "preprocessing = keras.Sequential([keras.layers.Rescaling(scale=1.0 / 255.0)])\n",
    "\n",
    "# Apply the preprocessing\n",
    "dataset = dataset.map(lambda x, y: (preprocessing(x, training=False), y))\n",
    "\n",
    "\n",
    "# Define the feeding data for the converter\n",
    "def representative_dataset():\n",
    "    for images, _ in dataset.take(100):\n",
    "        yield [images]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8afa5e",
   "metadata": {},
   "source": [
    "# 1. Transform models:\n",
    "\n",
    "Here we are showing the transformation from a pre-trained `tf-keras` model into the `tflite` and `tf-lite-quant` versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcdbdfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"BaseModel\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Backbone (KerasLayer)       (None, 256)               218544    \n",
      "                                                                 \n",
      " BatchNorm1 (BatchNormaliza  (None, 256)               1024      \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " Output (Dense)              (None, 7)                 1799      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221367 (864.71 KB)\n",
      "Trainable params: 215383 (841.34 KB)\n",
      "Non-trainable params: 5984 (23.38 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load model from pre-trained checkpoint\n",
    "base_model = tf.keras.models.load_model(MODEL_PATH)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05470115",
   "metadata": {},
   "source": [
    "## 1. Standard TF-LITE:\n",
    "This is a `tflite` model, still using `float32` for all parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ad891378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmphpvrgs71/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmphpvrgs71/assets\n",
      "2024-01-16 16:24:32.341707: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-16 16:24:32.341760: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-16 16:24:32.342147: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmphpvrgs71\n",
      "2024-01-16 16:24:32.352877: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-16 16:24:32.352896: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmphpvrgs71\n",
      "2024-01-16 16:24:32.390860: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-16 16:24:32.734090: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmphpvrgs71\n",
      "2024-01-16 16:24:32.890191: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 548095 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 96, % non-converted = 62.50 %\n",
      " * 60 ARITH ops\n",
      "\n",
      "- arith.constant:   60 occurrences  (f32: 58, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
    "tflite_model = converter.convert()\n",
    "store_model(tflite_model, MODEL_TFLITE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249aed2d",
   "metadata": {},
   "source": [
    "## 2. Dynamic range quantization\n",
    "\n",
    "Here we are still using `float32` for input and output, but most of the weights will be converted to `8-bit` precision. Activations are also quantized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "54278e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp2_xk6aog/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp2_xk6aog/assets\n",
      "2024-01-16 16:28:00.506527: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-16 16:28:00.506545: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-16 16:28:00.506747: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp2_xk6aog\n",
      "2024-01-16 16:28:00.517803: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-16 16:28:00.517822: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp2_xk6aog\n",
      "2024-01-16 16:28:00.554196: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-16 16:28:00.901910: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp2_xk6aog\n",
      "2024-01-16 16:28:01.059231: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 552484 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 41, Total Ops 96, % non-converted = 42.71 %\n",
      " * 41 ARITH ops\n",
      "\n",
      "- arith.constant:   41 occurrences  (f32: 39, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (uq_8: 19)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model_quant = converter.convert()\n",
    "store_model(tflite_model_quant, MODEL_QUANT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3bdab",
   "metadata": {},
   "source": [
    "## 3. Full integer quantization\n",
    "\n",
    "Basically here we are quantisizing also quantizing activations ( and input/output ). Fro this we need to calibrate the quantization of those values, and hence, we need to feed some data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca8beb4",
   "metadata": {},
   "source": [
    "### 3.1 Integer with float fallback:\n",
    "\n",
    "Here we are still using float implementation when integer ops are not available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4658d3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp4v22h3lk/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp4v22h3lk/assets\n",
      "/Users/vvcastro/.conda/envs/arduino/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-16 16:44:42.403160: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-16 16:44:42.403174: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-16 16:44:42.403398: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp4v22h3lk\n",
      "2024-01-16 16:44:42.415509: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-16 16:44:42.415525: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp4v22h3lk\n",
      "2024-01-16 16:44:42.455595: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-16 16:44:42.807599: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp4v22h3lk\n",
      "2024-01-16 16:44:43.067205: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 663807 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 96, % non-converted = 62.50 %\n",
      " * 60 ARITH ops\n",
      "\n",
      "- arith.constant:   60 occurrences  (f32: 58, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: FLOAT32, output_inference_type: FLOAT32\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.float16,\n",
    "]\n",
    "converter.representative_dataset = representative_dataset\n",
    "tflite_quant_model = converter.convert()\n",
    "store_model(tflite_quant_model, MODEL_QUANT_INT_FLOAT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116e7eb6",
   "metadata": {},
   "source": [
    "### 3.3 Integer only:\n",
    "\n",
    "Finally, this is a model with `input` and `output` as `uint8`. This should reduce memory usage to its maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "413c58ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp0c59lffy/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp0c59lffy/assets\n",
      "/Users/vvcastro/.conda/envs/arduino/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-16 16:42:51.503987: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-16 16:42:51.504005: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-16 16:42:51.504248: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp0c59lffy\n",
      "2024-01-16 16:42:51.516343: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-16 16:42:51.516362: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp0c59lffy\n",
      "2024-01-16 16:42:51.557537: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-16 16:42:51.933837: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp0c59lffy\n",
      "2024-01-16 16:42:52.093409: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 589161 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 60, Total Ops 96, % non-converted = 62.50 %\n",
      " * 60 ARITH ops\n",
      "\n",
      "- arith.constant:   60 occurrences  (f32: 58, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: UINT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(base_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "]\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "store_model(tflite_model, MODEL_QUANT_FUL_INT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9530b9c0",
   "metadata": {},
   "source": [
    "Finally, this will export the model as a set of bytes for operating in the arduino:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4415d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!xxd -n model_tflite -i {BASE_QUANT_INT_FULL_MODEL} > outputs/model.cc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbfdc5-a5d1-4499-9df8-0836fe7ed2ff",
   "metadata": {},
   "source": [
    "# 2. Testing functionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7780e371-d8ea-4a89-9ba0-945936d76e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=BASE_QUANT_INT_FULL_MODEL)\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "beba8a3b-f8db-4cb4-8cda-3a225506b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(np.random.rand(112, 112, 3), axis=0).astype(np.uint8)\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "input_index = input_details[\"index\"]\n",
    "output_index = output_details[\"index\"]\n",
    "\n",
    "interpreter.set_tensor(input_index, test_image)\n",
    "interpreter.invoke()\n",
    "predictions = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83c3d348-2e0f-4f8c-99c5-e1c78cdc6169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93, -63,  74,  97, -30]], dtype=int8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8070b0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'serving_default_Backbone_input:0',\n",
       "  'index': 0,\n",
       "  'shape': array([  1, 112, 112,   3], dtype=int32),\n",
       "  'shape_signature': array([ -1, 112, 112,   3], dtype=int32),\n",
       "  'dtype': numpy.uint8,\n",
       "  'quantization': (0.003921568859368563, 0),\n",
       "  'quantization_parameters': {'scales': array([0.00392157], dtype=float32),\n",
       "   'zero_points': array([0], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_input_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50ef81db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 92,\n",
       "  'shape': array([1, 5], dtype=int32),\n",
       "  'shape_signature': array([-1,  5], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.016782592982053757, 33),\n",
       "  'quantization_parameters': {'scales': array([0.01678259], dtype=float32),\n",
       "   'zero_points': array([33], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dde6eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
