{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6de01d98-8561-4a46-86da-199a272537b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "BASE_MODEL = \"outputs/Mobile V1\"\n",
    "NUM_CLASSES = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81db97f1-82c1-438a-bec3-74cef319e65c",
   "metadata": {},
   "source": [
    "Define the basic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a401878f-f5a5-4bc9-b7d5-595ebc48078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"outputs/Mobile_V1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Preprocessing (Rescaling)   (None, 112, 112, 3)       0         \n",
      "                                                                 \n",
      " Backbone (KerasLayer)       (None, 256)               218544    \n",
      "                                                                 \n",
      " Output (Dense)              (None, 5)                 1285      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 219829 (858.71 KB)\n",
      "Trainable params: 214357 (837.33 KB)\n",
      "Non-trainable params: 5472 (21.38 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    layers = [\n",
    "        layers.Rescaling(scale=(1./127.5), offset=-1, name=\"Preprocessing\"),  \n",
    "        hub.KerasLayer(\n",
    "            handle=f\"{BASE_MODEL}/features\",\n",
    "            trainable=True,\n",
    "            arguments=dict(batch_norm_momentum=0.997),\n",
    "            name=\"Backbone\"\n",
    "        ),\n",
    "        layers.Dense(NUM_CLASSES, activation=None, name=\"Output\")\n",
    "    ],\n",
    "    name=f'{BASE_MODEL.replace(\" \", \"_\")}'\n",
    ")\n",
    "\n",
    "model.build([None, 112, 112, 3])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e76da9-6ced-452b-97ac-be44b7fff94d",
   "metadata": {},
   "source": [
    "Check the final sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "facc7acf-dd21-4a8d-acd8-b5310dca0fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs/Mobile V1/base_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: outputs/Mobile V1/base_model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp0tn2mk89/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp0tn2mk89/assets\n",
      "2024-01-13 20:19:55.901749: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-13 20:19:55.901776: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-13 20:19:55.906201: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp0tn2mk89\n",
      "2024-01-13 20:19:55.921274: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-13 20:19:55.921305: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp0tn2mk89\n",
      "2024-01-13 20:19:55.955503: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-01-13 20:19:55.972329: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-13 20:19:56.412798: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp0tn2mk89\n",
      "2024-01-13 20:19:56.586220: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 680021 microseconds.\n",
      "2024-01-13 20:19:56.802821: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 61, Total Ops 99, % non-converted = 61.62 %\n",
      " * 61 ARITH ops\n",
      "\n",
      "- arith.constant:   61 occurrences  (f32: 59, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpus9h5whl/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpus9h5whl/assets\n",
      "2024-01-13 20:20:03.412529: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-13 20:20:03.412554: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-13 20:20:03.412891: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpus9h5whl\n",
      "2024-01-13 20:20:03.426576: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-13 20:20:03.426601: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpus9h5whl\n",
      "2024-01-13 20:20:03.476319: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-13 20:20:03.901308: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpus9h5whl\n",
      "2024-01-13 20:20:04.071268: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 658379 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 42, Total Ops 99, % non-converted = 42.42 %\n",
      " * 42 ARITH ops\n",
      "\n",
      "- arith.constant:   42 occurrences  (f32: 40, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "\n",
      "  (uq_8: 19)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "# Full size model ~2MB | ~3.9MB\n",
    "keras.saving.save_model(model, f'{BASE_MODEL}/base_model')\n",
    "\n",
    "# TFLite conversion ~800KB | ~1.6MB\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(f'{BASE_MODEL}/model-lite/model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "# TFLITE quant version ~292KB | ~574KB\n",
    "converter.optimizations = [ tf.lite.Optimize.DEFAULT ]\n",
    "tflite_quant_model = converter.convert()\n",
    "with open(f'{BASE_MODEL}/model-quant/model.tflite', 'wb') as f:\n",
    "  f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be038954-6287-4fbd-9b6e-cf0a03bcc1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpghq78xbw/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpghq78xbw/assets\n",
      "/Users/vvcastro/.conda/envs/arduino/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-13 20:20:19.286462: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-13 20:20:19.286487: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-13 20:20:19.286775: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpghq78xbw\n",
      "2024-01-13 20:20:19.301780: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-13 20:20:19.301805: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpghq78xbw\n",
      "2024-01-13 20:20:19.352430: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-13 20:20:19.842403: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpghq78xbw\n",
      "2024-01-13 20:20:20.032203: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 745428 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 61, Total Ops 99, % non-converted = 61.62 %\n",
      " * 61 ARITH ops\n",
      "\n",
      "- arith.constant:   61 occurrences  (f32: 59, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 2)\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "# TFLITE quant version ~322KB | ~649KB\n",
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = np.random.rand(1, 112, 112, 3)\n",
    "        yield [ data.astype(np.float32) ]\n",
    "\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [ tf.lite.OpsSet.TFLITE_BUILTINS_INT8 ]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_quant_full_model = converter.convert()\n",
    "with open(f'{BASE_MODEL}/model-quant-full/model.tflite', 'wb') as f:\n",
    "  f.write(tflite_quant_full_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbfdc5-a5d1-4499-9df8-0836fe7ed2ff",
   "metadata": {},
   "source": [
    "## Testing functionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7780e371-d8ea-4a89-9ba0-945936d76e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"./Mobile V1/model-quant-full/model.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beba8a3b-f8db-4cb4-8cda-3a225506b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(np.random.rand(112, 112, 3), axis=0).astype(np.int8)\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter.set_tensor(input_index, test_image)\n",
    "interpreter.invoke()\n",
    "predictions = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9922e5de-ebb1-4e8a-8284-fe97a13ad203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 91,\n",
       "  'shape': array([1, 6], dtype=int32),\n",
       "  'shape_signature': array([-1,  6], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.020725928246974945, -73),\n",
       "  'quantization_parameters': {'scales': array([0.02072593], dtype=float32),\n",
       "   'zero_points': array([-73], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3d348-2e0f-4f8c-99c5-e1c78cdc6169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
