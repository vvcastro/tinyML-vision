{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de01d98-8561-4a46-86da-199a272537b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-05 03:08:51.342549: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "NUM_CLASSES = 6\n",
    "BASE_MODEL = \"Mobile V1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81db97f1-82c1-438a-bec3-74cef319e65c",
   "metadata": {},
   "source": [
    "Define the basic model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a401878f-f5a5-4bc9-b7d5-595ebc48078c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Mobile_V1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Backbone (KerasLayer)       (None, 256)               218544    \n",
      "                                                                 \n",
      " Output (Dense)              (None, 6)                 1542      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220086 (859.71 KB)\n",
      "Trainable params: 214614 (838.34 KB)\n",
      "Non-trainable params: 5472 (21.38 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    layers = [\n",
    "        hub.KerasLayer(\n",
    "            handle=f\"{BASE_MODEL}/features\",\n",
    "            trainable=True,\n",
    "            arguments=dict(batch_norm_momentum=0.997),\n",
    "            name=\"Backbone\"\n",
    "        ),\n",
    "        tf.keras.layers.Dense(NUM_CLASSES, activation=None, name=\"Output\")\n",
    "    ],\n",
    "    name=f'{BASE_MODEL.replace(\" \", \"_\")}'\n",
    ")\n",
    "\n",
    "model.build([None, 112, 112, 3])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e76da9-6ced-452b-97ac-be44b7fff94d",
   "metadata": {},
   "source": [
    "Check the final sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "facc7acf-dd21-4a8d-acd8-b5310dca0fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Mobile V1/model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Mobile V1/model/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp1fc06v5i/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp1fc06v5i/assets\n",
      "2024-01-05 03:20:50.799546: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-05 03:20:50.799567: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-05 03:20:50.799795: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp1fc06v5i\n",
      "2024-01-05 03:20:50.807233: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-05 03:20:50.807266: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp1fc06v5i\n",
      "2024-01-05 03:20:50.833769: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-05 03:20:51.042933: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmp1fc06v5i\n",
      "2024-01-05 03:20:51.120450: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 320656 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 59, Total Ops 95, % non-converted = 62.11 %\n",
      " * 59 ARITH ops\n",
      "\n",
      "- arith.constant:   59 occurrences  (f32: 57, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmparm6u5z6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmparm6u5z6/assets\n",
      "2024-01-05 03:20:56.093154: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-05 03:20:56.093174: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-05 03:20:56.093399: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmparm6u5z6\n",
      "2024-01-05 03:20:56.106870: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-05 03:20:56.106890: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmparm6u5z6\n",
      "2024-01-05 03:20:56.147343: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-05 03:20:56.522155: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmparm6u5z6\n",
      "2024-01-05 03:20:56.629219: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 535820 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 40, Total Ops 95, % non-converted = 42.11 %\n",
      " * 40 ARITH ops\n",
      "\n",
      "- arith.constant:   40 occurrences  (f32: 38, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "\n",
      "  (uq_8: 19)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n"
     ]
    }
   ],
   "source": [
    "# Full size model ~2MB | ~3.9MB\n",
    "keras.saving.save_model(model, f'{BASE_MODEL}/model')\n",
    "\n",
    "# TFLite conversion ~800KB | ~1.6MB\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "with open(f'{BASE_MODEL}/model-lite/model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "# TFLITE quant version ~292KB | ~574KB\n",
    "converter.optimizations = [ tf.lite.Optimize.DEFAULT ]\n",
    "tflite_quant_model = converter.convert()\n",
    "with open(f'{BASE_MODEL}/model-quant/model.tflite', 'wb') as f:\n",
    "  f.write(tflite_quant_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be038954-6287-4fbd-9b6e-cf0a03bcc1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpukaty95g/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpukaty95g/assets\n",
      "/Users/vvcastro/.conda/envs/arduino/lib/python3.11/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\n",
      "2024-01-05 03:21:01.175746: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
      "2024-01-05 03:21:01.175765: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
      "2024-01-05 03:21:01.175955: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpukaty95g\n",
      "2024-01-05 03:21:01.183401: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-01-05 03:21:01.183417: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpukaty95g\n",
      "2024-01-05 03:21:01.210675: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
      "2024-01-05 03:21:01.410652: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/5j/vfb1vn5d7mxd7fmy30glls2c0000gn/T/tmpukaty95g\n",
      "2024-01-05 03:21:01.490092: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 314137 microseconds.\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 59, Total Ops 95, % non-converted = 62.11 %\n",
      " * 59 ARITH ops\n",
      "\n",
      "- arith.constant:   59 occurrences  (f32: 57, i32: 2)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 14)\n",
      "  (f32: 13)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "\n",
      "  (f32: 1)\n",
      "  (f32: 1)\n",
      "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
     ]
    }
   ],
   "source": [
    "# TFLITE quant version ~322KB | ~649KB\n",
    "def representative_dataset():\n",
    "    for _ in range(100):\n",
    "        data = np.random.rand(1, 112, 112, 3)\n",
    "        yield [ data.astype(np.float32) ]\n",
    "\n",
    "converter.representative_dataset = representative_dataset\n",
    "converter.target_spec.supported_ops = [ tf.lite.OpsSet.TFLITE_BUILTINS_INT8 ]\n",
    "converter.inference_input_type = tf.int8\n",
    "converter.inference_output_type = tf.int8\n",
    "tflite_quant_full_model = converter.convert()\n",
    "with open(f'{BASE_MODEL}/model-quant-full/model.tflite', 'wb') as f:\n",
    "  f.write(tflite_quant_full_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbbfdc5-a5d1-4499-9df8-0836fe7ed2ff",
   "metadata": {},
   "source": [
    "## Testing functionalities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7780e371-d8ea-4a89-9ba0-945936d76e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"./Mobile V1/model-quant-full/model.tflite\")\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beba8a3b-f8db-4cb4-8cda-3a225506b7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(np.random.rand(112, 112, 3), axis=0).astype(np.int8)\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "interpreter.set_tensor(input_index, test_image)\n",
    "interpreter.invoke()\n",
    "predictions = interpreter.get_tensor(output_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9922e5de-ebb1-4e8a-8284-fe97a13ad203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'StatefulPartitionedCall:0',\n",
       "  'index': 91,\n",
       "  'shape': array([1, 6], dtype=int32),\n",
       "  'shape_signature': array([-1,  6], dtype=int32),\n",
       "  'dtype': numpy.int8,\n",
       "  'quantization': (0.020725928246974945, -73),\n",
       "  'quantization_parameters': {'scales': array([0.02072593], dtype=float32),\n",
       "   'zero_points': array([-73], dtype=int32),\n",
       "   'quantized_dimension': 0},\n",
       "  'sparsity_parameters': {}}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interpreter.get_output_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c3d348-2e0f-4f8c-99c5-e1c78cdc6169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
